{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "2K7bKb0i3Y7j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\TensorflowGPU\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pathlib\n",
    "!unzip /content/brain-image-clean.zip\n",
    "!unzip /content/archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "2K7bKb0i3Y7j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pathlib\n",
    "!unzip /content/brain-image-clean.zip\n",
    "!unzip /content/archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0Wa3qKD3Y7l",
    "outputId": "c2e1fe9a-1a26-409b-cb03-b705e0f0c34f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image Count: 2100 \n",
      " Test Image Count: 900\n"
     ]
    }
   ],
   "source": [
    "train_dir = pathlib.Path(\"C:/Users/USER/Downloads/Downloads/properdataset/train\")\n",
    "test_dir = pathlib.Path(\"C:/Users/USER/Downloads/Downloads/properdataset/test\")\n",
    "image_count_train = len(list(train_dir.glob('*/*.jpg')))\n",
    "image_count_test = len(list(test_dir.glob('*/*.jpg')))\n",
    "print(\"Train Image Count: {} \\n Test Image Count: {}\".format(image_count_train,image_count_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hELGpK7B3Y7l"
   },
   "source": [
    "## Create DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zqts_ti93Y7n"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJT2x-5R3Y7n",
    "outputId": "61ca44ec-aa09-47cc-d21f-535f771e49fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2100 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=None,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wqMaxFFK3Y7o",
    "outputId": "e6283915-202b-4445-8f38-3f8ef2f62462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_dir,\n",
    "  validation_split=None,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9CLG_e33Y7o",
    "outputId": "d61dde2a-eb31-4a7c-8e0d-c082ec24eaca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'yes']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A8hOizUI3Y7p"
   },
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "H1Ij8fS33Y7p"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKcRh87E3Y7p"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-h53mVa3Y7p",
    "outputId": "7ad7c5a6-a676-4e3b-e4f8-8b7303cfed28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/66 [====>.........................] - ETA: 9s - loss: 0.6511 - accuracy: 0.6953 "
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(255, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw6jXk4m3Y7p"
   },
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3DEjmLn3Y7q",
    "outputId": "89a5d585-76df-4aa4-a6b8-02bf15ebc5de"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'E:\\499a\\mansurbaramodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pQF9PsC03Y7q",
    "outputId": "ff687a6a-ee54-45a5-d4ad-73511af74a37"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,\n",
    "                          show_shapes=True,\n",
    "                          expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlh_ern83Y7q"
   },
   "source": [
    "## Fit, Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnfV8Nqk3Y7r"
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMNZheo63Y7r"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'accuracy']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    try:\n",
    "      name = metric.replace(\"_\",\" \").capitalize()\n",
    "      plt.plot(history.epoch, history.history[metric], label='Train')\n",
    "      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n",
    "      plt.xlabel('Epoch')\n",
    "      plt.ylabel(name)\n",
    "      if metric == 'loss':\n",
    "        plt.ylim([0, plt.ylim()[1]])\n",
    "      elif metric == 'auc':\n",
    "        plt.ylim([0.8,1])\n",
    "      else:\n",
    "        plt.ylim([0,1])\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "    except:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "j6A8mqOU3Y7r",
    "outputId": "e985c2ba-20a2-4034-da64-d1b538c75d79"
   },
   "outputs": [],
   "source": [
    "plot_metrics(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPAaa9Na3Y7r"
   },
   "source": [
    "# Model Testing on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2r6GnnQq3Y7r"
   },
   "outputs": [],
   "source": [
    "def list_files(dir,full_dir):\n",
    "    r = []\n",
    "    r1 = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            rr = os.path.join(root, name)\n",
    "            r.append(rr)\n",
    "    dd = {'local_path':r}\n",
    "    df = pd.DataFrame(dd)\n",
    "    return df\n",
    "\n",
    "def proccess(img1):\n",
    "  img = tf.keras.preprocessing.image.load_img(\n",
    "      img1, target_size=(img_height, img_width)\n",
    "  )\n",
    "  img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "  img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "  predictions = model.predict(img_array)\n",
    "  score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "  pred = class_names[np.argmax(score)]\n",
    "  score1 = 100 * np.max(score)\n",
    "\n",
    "  return pred, score1\n",
    "\n",
    "def new_col(col):\n",
    "    if col['Pred'] == 'yes' and col['Actual'] == 'yes':\n",
    "        return 1\n",
    "    elif col['Pred'] == 'no' and col['Actual'] == 'no':\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "\n",
    "def proccess1(df):\n",
    "  aa = []\n",
    "  bb = []\n",
    "  cc = []\n",
    "\n",
    "  for a,b in df.iterrows():\n",
    "    img = b['local_path']\n",
    "    pred, value = proccess(img)\n",
    "    pat = b['local_path']\n",
    "\n",
    "    val = pat.split('/')[4]\n",
    "\n",
    "    aa.append(pred)\n",
    "    bb.append(value)\n",
    "    cc.append(val)\n",
    "  vals = {\"Pred\":aa,\"Accurarcy\":bb,'Actual':cc}\n",
    "  df_test1 = pd.DataFrame(vals)\n",
    "  df_test1 = pd.concat([df,df_test1], axis=1)\n",
    "\n",
    "  df_test1['Check'] = df_test1.apply(lambda col: new_col (col),axis=1)\n",
    "\n",
    "  return df_test1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBGORAGu3Y7s"
   },
   "outputs": [],
   "source": [
    "fullpath = '../content/brain-image-clean/test'\n",
    "path = \"test\"\n",
    "\n",
    "df_test = list_files(fullpath, path)\n",
    "df_test1 = proccess1(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "s4T4FqrD3Y7s",
    "outputId": "322d3e8f-195d-4a3b-9ef2-6bd5f75fa790"
   },
   "outputs": [],
   "source": [
    "def new_col(col):\n",
    "    if col['Pred'] == 'yes':\n",
    "        return 1\n",
    "    else:\n",
    "      return 0\n",
    "def new_col2(col):\n",
    "    if col['Actual'] == 'yes':\n",
    "        return 1\n",
    "    else:\n",
    "      return 0\n",
    "df_test1['Pred1'] = df_test1.apply(lambda col: new_col (col),axis=1)\n",
    "df_test1['Actual1'] = df_test1.apply(lambda col: new_col2 (col),axis=1)\n",
    "df_test1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ijp75tSI3Y7s"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dIwx-Kol3Y7s",
    "outputId": "dd25daea-0d88-4938-9d22-4e8b143c286c"
   },
   "outputs": [],
   "source": [
    "df_test1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6_w51Gb3Y7s"
   },
   "source": [
    "## Accurarcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4YhhQjn3Y7s"
   },
   "source": [
    "### Test Accurarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FzkAM-O3Y7t",
    "outputId": "b5df7323-ad86-45f5-d3f0-3148c7c68ed1"
   },
   "outputs": [],
   "source": [
    "form = df_test1.Check.value_counts() / df_test1.Check.count()\n",
    "print('Accuracy is : {}'.format(form))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjlPYxWH3Y7t"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 845
    },
    "id": "3_Maudam3Y7t",
    "outputId": "64d7b120-7dfd-4145-c5d8-98b9e4605a34"
   },
   "outputs": [],
   "source": [
    "labels = df_test1['Actual1'].to_numpy().astype(int)\n",
    "predictions = df_test1['Pred1'].to_numpy().astype(int)\n",
    "cm = tf.math.confusion_matrix(labels=labels, predictions=predictions).numpy()\n",
    "ls = ['Non-Tumorous', 'Tumorous'] # your y labels()\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ls)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(xticks_rotation=50, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7acPNz0x3Y7t"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8BUQWqu3Y7t",
    "outputId": "2e8fa7d1-0531-409a-cb3a-9b9eab9e03e0"
   },
   "outputs": [],
   "source": [
    "acc = (cm[0][0] + cm[1][1]) / (cm[0][0] + cm[0][1]+ cm[1][1] + cm[1][0])\n",
    "TPR =  (cm[1][1]) / (cm[1][1] + cm[1][0])\n",
    "FPR = (cm[0][1]) / (cm[0][1] + cm[0][0])\n",
    "print(\"ACC: {}\\nTPR: {}\\n FPR: {}\".format(acc,TPR,FPR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Xv4GNTMl3Y7u",
    "outputId": "9445dd63-cf9f-448f-b71b-a546bf9d7be4"
   },
   "outputs": [],
   "source": [
    "df_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0AiO49p3Y7u",
    "outputId": "6a55be7b-3b4a-4773-91ee-082a71092d3b"
   },
   "outputs": [],
   "source": [
    "df_test1[df_test1[\"Check\"] == 0][['Actual',\"Pred\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ApEuVdUD3Y7u",
    "outputId": "f0103c37-3617-4ac3-d9c8-f064bba14b7b"
   },
   "outputs": [],
   "source": [
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_PPGLfe3Y7v"
   },
   "outputs": [],
   "source": [
    "df_test2= df_test1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMrbZPwZ3Y7v"
   },
   "outputs": [],
   "source": [
    "df_test3= df_test1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rd7UbGRt3Y7v"
   },
   "outputs": [],
   "source": [
    "df_test4 = pd.concat([df_test2,df_test3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "WplrGZ6D3Y7v",
    "outputId": "45d71541-fcae-4152-fd32-f25616d67385"
   },
   "outputs": [],
   "source": [
    "df_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cqk5u7A73Y7w",
    "outputId": "20beea6a-4e28-4823-d67c-acc479a74646"
   },
   "outputs": [],
   "source": [
    "for a,b in df_test4.iterrows():\n",
    "    img_path = (b['local_path'])\n",
    "    im = imageio.imread(img_path)\n",
    "\n",
    "    print(\"Actual: {} \\nPrediction: {}\".format(b['Actual'], b['Pred']))\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    print('==============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
